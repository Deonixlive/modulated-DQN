{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9b593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/deonix/maturarbeit-code/DQN-Implementations/DQN/DoubleDQNv2.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 01:55:40.580533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 01:55:40.710502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 01:55:40.710774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 01:55:40.715322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-20 01:55:40.716872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 01:55:40.717105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 01:55:40.717254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 01:55:42.334797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 01:55:42.336292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 01:55:42.336485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 01:55:42.338496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3948 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:1f:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from DQN.modulatedDQN import Agent\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import losses\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5472f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#agent and environment optimized for Atari games\n",
    "#https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf\n",
    "\n",
    "class AtariGame:\n",
    "    def __init__(self, env_name, render_mode=None, name=None):\n",
    "        self.name = name\n",
    "        self.sample_batch_size = 32\n",
    "        self.episodes          = 5e6\n",
    "        self.env_name          = env_name\n",
    "        self.render_mode       = render_mode\n",
    "        self.env               = wrap_deepmind(env = make_atari(self.env_name, render_mode=render_mode),\n",
    "                                               frame_stack=True, scale=True)\n",
    "        self.frame_skip        = 4 #skip every 4th frame\n",
    "        #84x84 greyscale\n",
    "        self.reduzed_size      = (84, 84, self.frame_skip) #, greyscale(1), 84x84, 4 Pictures, \n",
    "        self.state_size        = self.reduzed_size\n",
    "        self.action_size       = self.env.action_space.n\n",
    "        self.termination_index = 10000\n",
    "        self.history           = []\n",
    "        self.save_freq         = 10000\n",
    "        self.update_freq       = 10000 #update target every 10k frames\n",
    "        self.random_min        = 50000\n",
    "        self.agent             = Agent(self.state_size, self.action_size, \n",
    "                                       #Parameters taken from Deepmind Breakout AI\n",
    "                                       #input model layers as keras.layers objects\n",
    "                                       anatomy=[layers.Conv2D(16,8,strides=4,activation=activations.relu),\n",
    "                                                layers.Conv2D(64,4,strides=2,activation=activations.relu),\n",
    "                                                layers.Conv2D(64,3,strides=2,activation=activations.relu),\n",
    "                                                layers.Flatten(),\n",
    "                                                layers.Dense(512, activation=activations.linear)],\n",
    "                                       name=f\"{self.env_name}-DoubleDQN\",\n",
    "                                       linear_decrease=True,\n",
    "                                       epsilon=1,\n",
    "                                       epsilon_decay=0.9/31000/4,\n",
    "                                       epsilon_min=0.1,\n",
    "                                       model_verbose=0,\n",
    "                                       lr=0.00025,\n",
    "                                       gamma=0.99,\n",
    "                                       optimizer=keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0),\n",
    "                                       loss_function=losses.Huber(),\n",
    "                                       max_memory_size=1e5\n",
    "                                       )\n",
    "        #print(self.state_size, self.action_size)\n",
    "    \n",
    "    def run(self, load_model = False, skip_training=False, overwrite_epsilon=-1, save=True, logs=False, log_freq=1):\n",
    "        #LOGS ARE ALWAYS ENABLED\n",
    "        logging.basicConfig(filename=f\"models/{self.agent.default_name}.log\",\n",
    "                level=logging.INFO,\n",
    "                format='%(levelname)s: %(asctime)s %(message)s',\n",
    "                datefmt='%d/%m/%Y %I:%M:%S')\n",
    "        \n",
    "        #if true, try to load existing model\n",
    "        if load_model:\n",
    "            self.agent.load_model(overwrite_epsilon=overwrite_epsilon)\n",
    "            \n",
    "        try:\n",
    "            training_batches = 0\n",
    "            frames = 0\n",
    "            for index_episode in range(int(self.episodes)):\n",
    "                state = self.env.reset() #returns a LazyFrame\n",
    "                state = np.array(state)\n",
    "                state_tensor = tf.expand_dims(state, 0)\n",
    "                done = False\n",
    "                score = 0 \n",
    "                q = 0\n",
    "                q_n = 0\n",
    "                \n",
    "                for index in range(0, self.termination_index):\n",
    "                    if index > self.frame_skip or frames > self.random_min:\n",
    "                        action = self.agent.pick_action(state_tensor) \n",
    "                    else:\n",
    "                        action = np.random.choice(self.agent.action_size)\n",
    "                     \n",
    "                    next_state, reward, done, _ = self.env.step(action)\n",
    "                    next_state = np.array(next_state)\n",
    "                    next_state_tensor = tf.expand_dims(next_state, 0)     \n",
    "                    score += reward\n",
    "                    #print(next_state.numpy().shape)\n",
    "                    #store Lazyframes\n",
    "                    self.agent.update_memory(state=state, \n",
    "                                             reward=reward, \n",
    "                                             action=action, \n",
    "                                             state_next=next_state, \n",
    "                                             done=done)\n",
    "                    \n",
    "                    if (index % self.frame_skip == 0) and not skip_training:\n",
    "                        if index > self.frame_skip:\n",
    "                            q += np.amax(self.agent.predict(state_tensor))\n",
    "                            q_n += 1\n",
    "\n",
    "                            training_batches += 1\n",
    "                            self.agent.replay(debug=False)  \n",
    "                            \n",
    "                    if (frames % self.update_freq) == 0:\n",
    "                        self.agent.update_target()\n",
    "                        logging.info(f\"MODEL UPDATE\")\n",
    "                        \n",
    "                    state = next_state\n",
    "                    state_tensor = next_state_tensor\n",
    "                    \n",
    "                    frames += 1\n",
    "                    \n",
    "                    if done:\n",
    "                        break\n",
    "                self.history.append(score)\n",
    "                if len(self.history) > 100:\n",
    "                    del self.history[:1]\n",
    "                \n",
    "                print(f\"Episode: {index_episode:-10}\")\n",
    "                print(f\"Score: {score:-12}\")\n",
    "                print(f\"Epsilon: {self.agent.exploration_rate}\")\n",
    "                print(\"\".join([\"_\" for i in range(10)]))\n",
    "                if logs and index_episode % log_freq == 0:\n",
    "                    running_reward = sum(self.history) / len(self.history)\n",
    "                    logging.info(f\"EPISODE: {index_episode}\")\n",
    "                    logging.info(f\"AVG LAST {len(self.history)} REWARDS: {running_reward:0.2f}\")\n",
    "                    \n",
    "                    if q_n != 0:\n",
    "                        logging.info(f\"AVG Q VALUE: {(q / q_n):.5f}\")\n",
    "                    logging.info(f\"SCORE: {score}\")\n",
    "                    logging.info(f\"DURATION (STEPS): {index}\")\n",
    "                    logging.info(str(self.agent))\n",
    "                    logging.info(\"\".join([\"-\" for i in range(12)]))\n",
    "                \n",
    "                if index_episode % self.save_freq == 0 and save and index_episode != 0:\n",
    "                    self.agent.save_model(name=\"EP\"+str(index_episode/1000)+\"k\", save_memory=False)\n",
    "                \n",
    "        except:\n",
    "            if save:\n",
    "                self.agent.save_model(name=\"ERROR\", save_memory=False)\n",
    "            logging.info(\"\".join([\"+\" for i in range(14)]))\n",
    "            logging.exception(\"An error has occured\")\n",
    "            logging.info(\"\".join([\"+\" for i in range(14)]))\n",
    "            \n",
    "        finally:\n",
    "            #save model upon interrupting\n",
    "            if logs or save:\n",
    "                logging.info(f\"TRAINING FINISHED AFTER {training_batches} BATCHES\")\n",
    "                logging.info(\"\".join([\"+\" for i in range(14)]))\n",
    "                if save:\n",
    "                    model_name = self.agent.build_name(name=\"FINISHED\")\n",
    "                    logging.info(f\"MODEL NAME: {model_name}\")\n",
    "                logging.info(\"\".join([\"+\" for i in range(14)]))\n",
    "            #print(training_batches)\n",
    "            if save:\n",
    "                self.agent.save_model(name=\"FINISHED\", save_memory=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #render modes: \"human\", None\n",
    "    atari = AtariGame(\"BreakoutNoFrameskip-v4\", render_mode=None)\n",
    "#     atari.run(load_model=False, skip_training=False, overwrite_epsilon=1, save=False, logs=True, log_freq=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cffceac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer Adam: lr=0.001\n",
      "\n",
      "                    NAME: DeepQNetwork\n",
      "                    INPUT SHAPE: (84, 84, 4), OUTPUT SHAPE: 4\n",
      "                    OPTIMIZER: <class 'keras.optimizers.optimizer_v2.adam.Adam'>\n",
      "                    LOSS FUNCTION: <class 'keras.losses.MeanSquaredError'>\n",
      "                    LEARNING RATE: 0.001\n",
      "                    TARGET_NETWORK: enabled-> True\n",
      "                                    target_updates->0\n",
      "                    MEMORY: 0/1000000 Â¦ 0.00%\n",
      "                    EPSILON: 1.000000\n",
      "                             min-> 0.0001\n",
      "                    ACTIONS TAKEN:  greedy-> 0\n",
      "                                    exploration-> 0\n",
      "                    REPLAY: batch_size-> 32\n",
      "                            gamma-> 0.95\n",
      "                            gradient_updates-> 0\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "env = make_atari(\"BreakoutNoFrameskip-v4\")\n",
    "env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "env1 = make_atari(\"BreakoutNoFrameskip-v4\")\n",
    "env.seed(1)\n",
    "env1.seed(1)\n",
    "agent = Agent(env.observation_space.shape, env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d364a44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "state = np.array(state)\n",
    "print(state.dtype)\n",
    "plt.imshow(state)\n",
    "plt.savefig(fname=\"Breakout_pre\",dpi=600)\n",
    "\n",
    "compressed = agent.replay_compress(state)\n",
    "uncompressed = agent.replay_unpack(compressed)\n",
    "\n",
    "np.equal(state, uncompressed).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bbc7a90",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "step() missing 1 required positional argument: 'action'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m state1 \u001b[38;5;241m=\u001b[39m env1\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m----> 3\u001b[0m state1 \u001b[38;5;241m=\u001b[39m \u001b[43menv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(state1)\n",
      "\u001b[0;31mTypeError\u001b[0m: step() missing 1 required positional argument: 'action'"
     ]
    }
   ],
   "source": [
    "state1 = env1.reset()\n",
    "\n",
    "state1 = env1.step()\n",
    "plt.imshow(state1)\n",
    "# plt.savefig(fname=\"Breakout_raw\",dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d1d404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad9b7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830fc61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
